{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-13T08:56:38.715048Z",
     "start_time": "2021-10-13T08:56:37.049435Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from Tushare_data_fetcher.ipynb\n"
     ]
    }
   ],
   "source": [
    "import Importer  # Help directly import Ipython notebooks\n",
    "# (Reference: https://nbviewer.jupyter.org/github/jupyter/notebook/blob/master/docs/source/examples/Notebook/Importing%20Notebooks.ipynb)\n",
    "import Tushare_data_fetcher\n",
    "import pymysql\n",
    "import pymssql\n",
    "import tushare as ts\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sqlalchemy\n",
    "import datetime\n",
    "import json\n",
    "import urllib.parse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Basic configurations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.1 Local configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "token = 'ce9611f48f0fe5d6fb5abe3303367254f1ff2836a0fbc2fa72e15e82'\n",
    "ts.set_token(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-13T08:56:31.662248Z",
     "start_time": "2021-10-13T08:56:31.651278Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('../config/config.json', 'r') as f:\n",
    "    config = json.load(f)\n",
    "con = pymysql.connect(**config)\n",
    "cur = con.cursor()\n",
    "alchemy_str = 'mysql+pymysql://' + config['user'] + ':' + config['password'] + \\\n",
    "    '@' + config['host'] + ':' + str(config['port']) + '/' + config['database']\n",
    "alchemy_engine = sqlalchemy.create_engine(alchemy_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-13T08:56:42.178325Z",
     "start_time": "2021-10-13T08:56:42.053853Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['asset_return', 'balance', 'cashflow', 'daily', 'est_earning', 'est_pe', 'finance', 'shibor']\n"
     ]
    }
   ],
   "source": [
    "cur.execute(\"show tables\")\n",
    "table_list = [tuple[0] for tuple in cur.fetchall()]\n",
    "print(table_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-13T08:56:46.138781Z",
     "start_time": "2021-10-13T08:56:46.075376Z"
    }
   },
   "source": [
    "### 0.2 Wind Database Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../config/wind_config.json', 'r') as f:\n",
    "    config_wind = json.load(f)\n",
    "conn_wind = pymssql.connect(**config_wind)\n",
    "cursor_wind = conn_wind.cursor()\n",
    "password_parse = urllib.parse.quote_plus(config_wind['password'])\n",
    "alchemy_str_wind = 'mssql+pymssql://' + config_wind['user'] + ':' + password_parse + \\\n",
    "    '@' + config_wind['host'] + ':1433' + '/' + \\\n",
    "    config_wind['database'] + '?charset=GBK'\n",
    "alchemy_engine_wind = sqlalchemy.create_engine(\n",
    "    alchemy_str_wind, encoding='GBK')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1. Create corresponding tables (Initialization) and fill with data from 2015-01-01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ATTENTION: The TABLE name would be automatically transformed to lower cases (i.e. Daily $\\rightarrow$ daily)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Only saving codes for indirect Tables are kept. The creation procedures are also deleted for simplicity.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Table Daliy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-08T16:14:32.296050Z",
     "start_time": "2021-09-08T16:14:32.284397Z"
    }
   },
   "outputs": [],
   "source": [
    "daily_create = '''\n",
    "    CREATE TABLE Daily(\n",
    "    ts_code VARCHAR(10) NOT NULL,\n",
    "    trade_date DATE NOT NULL,\n",
    "    turnover_rate NUMERIC(18,4),\n",
    "    turnover_rate_f NUMERIC(18,4),\n",
    "    pe_ttm NUMERIC(18,4),\n",
    "    pb NUMERIC(18,4),\n",
    "    total_share NUMERIC(38,4),\n",
    "    float_share NUMERIC(38,4),\n",
    "    total_mv NUMERIC(38,4),\n",
    "    circ_mv NUMERIC(38,4));\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.execute(daily_create)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-08T16:41:39.606836Z",
     "start_time": "2021-09-08T16:14:50.538203Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trade_cal = Tushare_data_fetcher.get_trade_calendar(start_date='20150101',\n",
    "                                                    end_date='20210831')\n",
    "for date in trade_cal:\n",
    "    daily_df = Tushare_data_fetcher.get_daily_indicators(date=date)\n",
    "    daily_df.to_sql(name='daily', con=alchemy_engine,\n",
    "                    if_exists='append', index=False)\n",
    "    print(f'{date}: Daily indicators saved.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Table Return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-09T09:22:31.000656Z",
     "start_time": "2021-09-09T09:22:30.986173Z"
    }
   },
   "outputs": [],
   "source": [
    "return_create = '''\n",
    "    CREATE TABLE asset_return(\n",
    "    ts_code VARCHAR(10) NOT NULL,\n",
    "    trade_date DATE NOT NULL,\n",
    "    close NUMERIC(18,4),\n",
    "    pre_close NUMERIC(18,4),\n",
    "    pct_chg NUMERIC(18,4),\n",
    "    vol NUMERIC(38,4),\n",
    "    amount NUMERIC(38,4));\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-09T17:08:27.323047Z",
     "start_time": "2021-09-09T17:08:23.855526Z"
    }
   },
   "outputs": [],
   "source": [
    "query = '''\n",
    "    SELECT Min(trade_date)\n",
    "    FROM asset_return;\n",
    "    '''\n",
    "q_df = pd.read_sql_query(query, con=alchemy_engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-09T17:09:40.689096Z",
     "start_time": "2021-09-09T17:09:40.675134Z"
    }
   },
   "outputs": [],
   "source": [
    "q_df.iloc[0, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Table Shibor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-09T12:44:01.552964Z",
     "start_time": "2021-09-09T12:44:01.535315Z"
    }
   },
   "outputs": [],
   "source": [
    "shibor_create = '''\n",
    "    CREATE TABLE shibor(\n",
    "    date DATE NOT NULL,\n",
    "    `on` NUMERIC(18,4),\n",
    "    1w NUMERIC(18,4),\n",
    "    2w NUMERIC(18,4),\n",
    "    1m NUMERIC(18,4),\n",
    "    3m NUMERIC(18,4),\n",
    "    6m NUMERIC(18,4),\n",
    "    9m NUMERIC(18,4),\n",
    "    1y NUMERIC(18,4));\n",
    "    '''\n",
    "# 在MySQL中，为了显式区分MySQL的关键字与普通字符，需要使用一个反引号``"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Table Finance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-09T14:51:23.716042Z",
     "start_time": "2021-09-09T14:51:23.710059Z"
    }
   },
   "outputs": [],
   "source": [
    "finance_create = '''\n",
    "    CREATE TABLE Finance(\n",
    "    ts_code VARCHAR(10) NOT NULL,\n",
    "    ann_date DATE,\n",
    "    f_ann_date DATE,\n",
    "    end_date DATE NOT NULL,\n",
    "    report_type INTEGER,\n",
    "    revenue NUMERIC(38,4),\n",
    "    n_income_attr_p NUMERIC(38,4));\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-09T14:51:42.023169Z",
     "start_time": "2021-09-09T14:51:33.604745Z"
    }
   },
   "outputs": [],
   "source": [
    "for year in range(2015, 2021):\n",
    "    period = str(year) + '1231'\n",
    "    finance_df = Tushare_data_fetcher.get_finance_indicators(period=period)\n",
    "    if (finance_df.empty == False):\n",
    "        finance_df.to_sql(name='finance',\n",
    "                          con=alchemy_engine,\n",
    "                          if_exists='append',\n",
    "                          index=False)\n",
    "        print(f'{year}:Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Table Cashflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-09T15:01:37.172698Z",
     "start_time": "2021-09-09T15:01:37.169438Z"
    }
   },
   "outputs": [],
   "source": [
    "cashflow_create = '''\n",
    "    CREATE TABLE Cashflow(\n",
    "    ts_code VARCHAR(10) NOT NULL,\n",
    "    ann_date DATE,\n",
    "    f_ann_date DATE,\n",
    "    end_date DATE NOT NULL,\n",
    "    report_type INTEGER,\n",
    "    n_cashflow_act NUMERIC(38,4),\n",
    "    im_net_cashflow_oper_act NUMERIC(38,4));\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-09T15:02:08.521271Z",
     "start_time": "2021-09-09T15:02:00.757975Z"
    }
   },
   "outputs": [],
   "source": [
    "for year in range(2015, 2021):\n",
    "    period = str(year) + '1231'\n",
    "    cashflow_df = Tushare_data_fetcher.get_cashflow_indicators(period=period)\n",
    "    if (cashflow_df.empty == False):\n",
    "        cashflow_df.to_sql(name='cashflow',\n",
    "                           con=alchemy_engine,\n",
    "                           if_exists='append',\n",
    "                           index=False)\n",
    "        print(f'{year}:Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Table Balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-09T15:02:33.111823Z",
     "start_time": "2021-09-09T15:02:33.102342Z"
    }
   },
   "outputs": [],
   "source": [
    "balance_create = '''\n",
    "    CREATE TABLE Balance(\n",
    "    ts_code VARCHAR(10) NOT NULL,\n",
    "    ann_date DATE,\n",
    "    f_ann_date DATE,\n",
    "    end_date DATE NOT NULL,\n",
    "    report_type INTEGER,\n",
    "    total_share NUMERIC(38,4),\n",
    "    total_assets NUMERIC(38,4),\n",
    "    total_cur_liab NUMERIC(38,4),\n",
    "    total_liab NUMERIC(38,4),\n",
    "    oth_eqt_tools_p_shr NUMERIC(38,4));\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-09T15:04:28.202397Z",
     "start_time": "2021-09-09T15:04:09.996968Z"
    }
   },
   "outputs": [],
   "source": [
    "for year in range(2015, 2021):\n",
    "    for suffix in ['0331', '0630', '0930', '1231']:\n",
    "        period = str(year) + suffix\n",
    "        balance_df = Tushare_data_fetcher.get_balance_indicators(period=period)\n",
    "        if (balance_df.empty == False):\n",
    "            balance_df.to_sql(name='balance',\n",
    "                              con=alchemy_engine,\n",
    "                              if_exists='append',\n",
    "                              index=False)\n",
    "            print(f'{period}:Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Table EST_PE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EST_PE_create = '''\n",
    "    CREATE TABLE est_pe(\n",
    "    wind_code VARCHAR(10) NOT NULL,\n",
    "    est_date DATE,\n",
    "    rolling_type VARCHAR(10),\n",
    "    est_pe NUMERIC(38,4));\n",
    "    '''\n",
    "cur.execute(EST_PE_create)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "EST_PE_query = '''\n",
    "                SELECT S_INFO_WINDCODE AS wind_code, EST_DT AS est_date,\n",
    "                    ROLLING_TYPE AS rolling_type, EST_PE as est_pe\n",
    "                FROM ASHARECONSENSUSROLLINGDATA\n",
    "                WHERE EST_DT > '20210801'\n",
    "                AND (ROLLING_TYPE = 'FTTM' OR ROLLING_TYPE = 'FY1');\n",
    "            '''\n",
    "EST_PE_df = pd.read_sql(EST_PE_query, con=alchemy_engine_wind)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Table EST_Earning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "OperationalError",
     "evalue": "(1050, \"Table 'est_earning' already exists\")",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16076/922971527.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m     est_earning NUMERIC(38,4));\n\u001b[0;32m      7\u001b[0m     '''\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mcur\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mEST_EARNING_create\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\lab\\lib\\site-packages\\pymysql\\cursors.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, query, args)\u001b[0m\n\u001b[0;32m    146\u001b[0m         \u001b[0mquery\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmogrify\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    147\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 148\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_query\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    149\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_executed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mquery\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    150\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\lab\\lib\\site-packages\\pymysql\\cursors.py\u001b[0m in \u001b[0;36m_query\u001b[1;34m(self, q)\u001b[0m\n\u001b[0;32m    308\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_last_executed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mq\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    309\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_clear_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 310\u001b[1;33m         \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    311\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    312\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrowcount\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\lab\\lib\\site-packages\\pymysql\\connections.py\u001b[0m in \u001b[0;36mquery\u001b[1;34m(self, sql, unbuffered)\u001b[0m\n\u001b[0;32m    546\u001b[0m             \u001b[0msql\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msql\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"surrogateescape\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_execute_command\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCOMMAND\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOM_QUERY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msql\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 548\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_affected_rows\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_read_query_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munbuffered\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0munbuffered\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    549\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_affected_rows\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    550\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\lab\\lib\\site-packages\\pymysql\\connections.py\u001b[0m in \u001b[0;36m_read_query_result\u001b[1;34m(self, unbuffered)\u001b[0m\n\u001b[0;32m    773\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    774\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMySQLResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 775\u001b[1;33m             \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    776\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    777\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mserver_status\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\lab\\lib\\site-packages\\pymysql\\connections.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1154\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1155\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1156\u001b[1;33m             \u001b[0mfirst_packet\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnection\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_read_packet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1157\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1158\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mfirst_packet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_ok_packet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\lab\\lib\\site-packages\\pymysql\\connections.py\u001b[0m in \u001b[0;36m_read_packet\u001b[1;34m(self, packet_type)\u001b[0m\n\u001b[0;32m    723\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_result\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munbuffered_active\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    724\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munbuffered_active\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 725\u001b[1;33m             \u001b[0mpacket\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_for_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    726\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mpacket\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    727\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\lab\\lib\\site-packages\\pymysql\\protocol.py\u001b[0m in \u001b[0;36mraise_for_error\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    219\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mDEBUG\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    220\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"errno =\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrno\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 221\u001b[1;33m         \u001b[0merr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_mysql_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    222\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    223\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\lab\\lib\\site-packages\\pymysql\\err.py\u001b[0m in \u001b[0;36mraise_mysql_exception\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    141\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0merrorclass\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    142\u001b[0m         \u001b[0merrorclass\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mInternalError\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0merrno\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m1000\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mOperationalError\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 143\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0merrorclass\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merrno\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mOperationalError\u001b[0m: (1050, \"Table 'est_earning' already exists\")"
     ]
    }
   ],
   "source": [
    "EST_EARNING_create = '''\n",
    "    CREATE TABLE est_earning(\n",
    "    wind_code VARCHAR(10) NOT NULL,\n",
    "    est_date DATE,\n",
    "    rolling_type VARCHAR(10),\n",
    "    est_earning NUMERIC(38,4));\n",
    "    '''\n",
    "cur.execute(EST_EARNING_create)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Earning_Growth_EST_query = '''\n",
    "                        SELECT S_INFO_WINDCODE AS wind_code , EST_DT AS est_date,\n",
    "                        ROLLING_TYPE AS rolling_type, NET_PROFIT AS est_earning\n",
    "                        FROM ASHARECONSENSUSROLLINGDATA\n",
    "                        WHERE EST_DT > '20210801'\n",
    "                        AND (ROLLING_TYPE = 'YOY' OR ROLLING_TYPE = 'YOY2')\n",
    "                        '''\n",
    "EST_Earning_df = pd.read_sql(Earning_Growth_EST_query, con=alchemy_engine_wind)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Class DataSaver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataSaver:\n",
    "    def __init__(self, token, market_port='000985.CSI'):\n",
    "        # Set market portfolio\n",
    "        self.market_port = market_port\n",
    "\n",
    "        # Tushare\n",
    "        self.token = token\n",
    "        ts.set_token(self.token)\n",
    "\n",
    "        # Local database\n",
    "        with open('../config/config.json', 'r') as f:\n",
    "            config = json.load(f)\n",
    "        con = pymysql.connect(**config)\n",
    "        cur = con.cursor()\n",
    "        alchemy_str = 'mysql+pymysql://' + config['user'] + ':' + config['password'] + \\\n",
    "            '@' + config['host'] + ':' + \\\n",
    "            str(config['port']) + '/' + config['database']\n",
    "        self.alchemy_engine = sqlalchemy.create_engine(alchemy_str)\n",
    "\n",
    "        # Wind database\n",
    "        with open('../config/wind_config.json', 'r') as f:\n",
    "            config_wind = json.load(f)\n",
    "        conn_wind = pymssql.connect(**config_wind)\n",
    "        cursor_wind = conn_wind.cursor()\n",
    "        password_parse = urllib.parse.quote_plus(config_wind['password'])\n",
    "        alchemy_str_wind = 'mssql+pymssql://' + config_wind['user'] + ':' + password_parse + \\\n",
    "            '@' + config_wind['host'] + ':1433' + '/' + \\\n",
    "            config_wind['database'] + '?charset=GBK'\n",
    "        self.alchemy_engine_wind = sqlalchemy.create_engine(\n",
    "            alchemy_str_wind, encoding='GBK')\n",
    "        return\n",
    "\n",
    "    def set_token(self, token):\n",
    "        self.token = token\n",
    "        ts.set_token(self.token)\n",
    "        return\n",
    "\n",
    "    def set_market_portfolio(self, mar_port):\n",
    "        self.market_port = mar_port\n",
    "        return\n",
    "\n",
    "    def _save_daily_indicators(self, start_date, end_date):  # 测试通过\n",
    "        trade_cal = Tushare_data_fetcher.get_trade_calendar(\n",
    "            start_date=start_date, end_date=end_date)\n",
    "        for date in trade_cal:\n",
    "            daily_df = Tushare_data_fetcher.get_daily_indicators(date=date)\n",
    "            if (daily_df.empty == False):\n",
    "                daily_df.to_sql(name='daily',\n",
    "                                con=self.alchemy_engine,\n",
    "                                if_exists='append',\n",
    "                                index=False)\n",
    "        return daily_df.empty == False\n",
    "\n",
    "    def _save_stock_return(self, start_date, end_date):  # 测试通过\n",
    "        if (start_date != end_date):\n",
    "            stock_return_df = Tushare_data_fetcher.get_interval_stock_return(\n",
    "                start_date=start_date, end_date=end_date, token=self.token)\n",
    "        else:\n",
    "            stock_return_df = Tushare_data_fetcher.get_daily_stock_return(\n",
    "                start_date)\n",
    "        if (stock_return_df.empty == False):\n",
    "            stock_return_df.to_sql(name='asset_return',\n",
    "                                   con=self.alchemy_engine,\n",
    "                                   if_exists='append',\n",
    "                                   index=False)\n",
    "        return stock_return_df.empty == False\n",
    "\n",
    "    def _save_index_return(self, start_date, end_date):  # 测试通过\n",
    "        index_return_df = Tushare_data_fetcher.get_interval_market_portfolio_return(\n",
    "            start_date=start_date, end_date=end_date, ts_code=self.market_port)\n",
    "        if (index_return_df.empty == False):\n",
    "            index_return_df.to_sql(name='asset_return',\n",
    "                                   con=self.alchemy_engine,\n",
    "                                   if_exists='append',\n",
    "                                   index=False)\n",
    "        return index_return_df.empty == False\n",
    "\n",
    "    def _save_shibor(self, start_date, end_date):  # 测试通过\n",
    "        shibor_df = Tushare_data_fetcher.get_interval_shibor(\n",
    "            start_date=start_date, end_date=end_date)\n",
    "        if (shibor_df.empty == False):\n",
    "            shibor_df.to_sql(name='shibor',\n",
    "                             con=self.alchemy_engine,\n",
    "                             if_exists='append',\n",
    "                             index=False)\n",
    "        return shibor_df.empty == False\n",
    "\n",
    "    def _save_finance(self, start_date, end_date):  # 测试通过\n",
    "        start_year = start_date[:4]\n",
    "        end_year = end_date[:4]\n",
    "        for year in range(int(start_year), int(end_year) + 1):\n",
    "            period = str(year) + '1231'\n",
    "            finance_df = Tushare_data_fetcher.get_finance_indicators(\n",
    "                period=period)\n",
    "            if (finance_df.empty == False):\n",
    "                finance_df.to_sql(name='finance',\n",
    "                                  con=self.alchemy_engine,\n",
    "                                  if_exists='append',\n",
    "                                  index=False)\n",
    "        return\n",
    "\n",
    "    def _save_cashflow(self, start_date, end_date):  # 测试通过\n",
    "        start_year = start_date[:4]\n",
    "        end_year = end_date[:4]\n",
    "        for year in range(int(start_year), int(end_year) + 1):\n",
    "            period = str(year) + '1231'\n",
    "            cashflow_df = Tushare_data_fetcher.get_cashflow_indicators(\n",
    "                period=period)\n",
    "            if (cashflow_df.empty == False):\n",
    "                cashflow_df.to_sql(name='cashflow',\n",
    "                                   con=self.alchemy_engine,\n",
    "                                   if_exists='append',\n",
    "                                   index=False)\n",
    "        return\n",
    "\n",
    "    def _save_balance(self,\n",
    "                      start_date,\n",
    "                      end_date,\n",
    "                      report_date=['0331', '0630', '0930', '1231']):  # 测试通过\n",
    "        start_year = start_date[:4]\n",
    "        end_year = end_date[:4]\n",
    "        for year in range(int(start_year), int(end_year) + 1):\n",
    "            for suffix in report_date:\n",
    "                period = str(year) + suffix\n",
    "                balance_df = Tushare_data_fetcher.get_balance_indicators(\n",
    "                    period=period)\n",
    "                if (balance_df.empty == False):\n",
    "                    balance_df.to_sql(name='balance',\n",
    "                                      con=self.alchemy_engine,\n",
    "                                      if_exists='append',\n",
    "                                      index=False)\n",
    "        return\n",
    "\n",
    "    def _save_est_pe(self, start_date, end_date):\n",
    "        EST_PE_query = f'''\n",
    "                SELECT S_INFO_WINDCODE AS wind_code, EST_DT AS est_date,\n",
    "                    ROLLING_TYPE AS rolling_type, EST_PE as est_pe\n",
    "                FROM ASHARECONSENSUSROLLINGDATA\n",
    "                WHERE EST_DT BETWEEN \\'{start_date}\\' AND \\'{end_date }\\'\n",
    "                AND (ROLLING_TYPE = 'FTTM' OR ROLLING_TYPE = 'FY1');\n",
    "            '''\n",
    "        EST_PE_df = pd.read_sql(EST_PE_query, con=self.alchemy_engine_wind)\n",
    "        EST_PE_df.to_sql(name='est_pe', con=self.alchemy_engine,\n",
    "                         if_exists='append', index=False)\n",
    "        return EST_PE_df.emptyty == False\n",
    "\n",
    "    def _save_est_earning(self, start_date, end_date):\n",
    "        Earning_Growth_EST_query = f'''\n",
    "                            SELECT S_INFO_WINDCODE AS wind_code , EST_DT AS est_date,\n",
    "                            ROLLING_TYPE AS rolling_type, NET_PROFIT AS est_earning\n",
    "                            FROM ASHARECONSENSUSROLLINGDATA\n",
    "                            WHERE EST_DT BETWEEN \\'{start_date}\\' AND \\'{end_date }\\'\n",
    "                            AND (ROLLING_TYPE = 'YOY' OR ROLLING_TYPE = 'YOY2')\n",
    "                            '''\n",
    "        EST_Earning_df = pd.read_sql(\n",
    "            Earning_Growth_EST_query, con=self.alchemy_engine_wind)\n",
    "        EST_Earning_df.to_sql(name='est_earning', con=self.alchemy_engine,\n",
    "                              if_exists='append', index=False)\n",
    "        return EST_Earning_df.empty == False\n",
    "\n",
    "    def _save_all_daily_data(self, start_date, end_date, test_mode=False):  # 可推测测试通过\n",
    "        print(f'Effective date: {start_date} - {end_date}')\n",
    "        if(test_mode == False):  # 由于函数可正常运行，测试阶段仅进行实际区间输出\n",
    "            if (self._save_daily_indicators(start_date, end_date)):\n",
    "                print('Daily saved successfully!')\n",
    "            if (self._save_stock_return(start_date, end_date)):\n",
    "                print('Stock return saved successfully!')\n",
    "            if (self._save_index_return(start_date, end_date)):\n",
    "                print('Index return saved successfully!')\n",
    "            if (self._save_shibor(start_date, end_date)):\n",
    "                print('Shibor saved successfully!')\n",
    "            if (self._save_est_pe(start_date, end_date)):\n",
    "                print('EST_PE saved successfully!')\n",
    "            if (self._save_est_earning(start_date, end_date)):\n",
    "                print('EST_EARNING saved successfully!')\n",
    "        return\n",
    "\n",
    "    def save_all_quarter_data(self, start_date,\n",
    "                              end_date):  # ATTENTION: 不保证覆盖问题，应当自行检查日期\n",
    "        # 可推测测试通过\n",
    "        self._save_finance(start_date, end_date)\n",
    "        print('Finance saved successfully!')\n",
    "        self._save_cashflow(start_date, end_date)\n",
    "        print('Cashflow saved successfully!')\n",
    "        self._save_balance(start_date, end_date)\n",
    "        print('Balance saved successfully!')\n",
    "        return\n",
    "\n",
    "    def save_all_daily_data(self, start_date, end_date, test_mode=False):\n",
    "        # 日期区间测试通过，据此可以推测函数功能通过测试\n",
    "        start_query = '''\n",
    "            SELECT MIN(trade_date)\n",
    "            FROM asset_return;\n",
    "            '''\n",
    "        start_query_df = pd.read_sql_query(start_query,\n",
    "                                           con=self.alchemy_engine)\n",
    "        cur_start_date = start_query_df.iloc[0, 0].strftime('%Y%m%d')\n",
    "\n",
    "        end_query = '''\n",
    "            SELECT MAX(trade_date)\n",
    "            FROM asset_return;\n",
    "            '''\n",
    "        end_query_df = pd.read_sql_query(end_query, con=self.alchemy_engine)\n",
    "        cur_end_date = end_query_df.iloc[0, 0].strftime('%Y%m%d')\n",
    "\n",
    "        if (start_date < cur_start_date):\n",
    "            if (end_date < cur_start_date):\n",
    "                self._save_all_daily_data(start_date, end_date, test_mode)\n",
    "            else:\n",
    "                temp_end_datetime = start_query_df.iloc[\n",
    "                    0, 0] - datetime.timedelta(days=1)\n",
    "                temp_end_date = temp_end_datetime.strftime('%Y%m%d')\n",
    "                self._save_all_daily_data(start_date, temp_end_date, test_mode)\n",
    "\n",
    "        if (end_date > cur_end_date):\n",
    "            if (start_date > cur_end_date):\n",
    "                self._save_all_daily_data(start_date, end_date, test_mode)\n",
    "            else:\n",
    "                temp_start_datetime = end_query_df.iloc[\n",
    "                    0, 0] + datetime.timedelta(days=1)\n",
    "                temp_start_date = temp_start_datetime.strftime('%Y%m%d')\n",
    "                self._save_all_daily_data(temp_start_date, end_date, test_mode)\n",
    "        return\n",
    "\n",
    "    def update_daily_to_date(self, test_mode=False):  # 通过测试\n",
    "        end_query = '''\n",
    "            SELECT MAX(trade_date)\n",
    "            FROM asset_return;\n",
    "            '''\n",
    "        end_query_df = pd.read_sql_query(end_query, con=self.alchemy_engine)\n",
    "        temp_start_datetime = end_query_df.iloc[0,\n",
    "                                                0] + datetime.timedelta(days=1)\n",
    "        temp_start_date = temp_start_datetime.strftime('%Y%m%d')\n",
    "\n",
    "        yesterday_datetime = datetime.datetime.now() - datetime.timedelta(\n",
    "            days=1)\n",
    "        yesterday_date = yesterday_datetime.strftime('%Y%m%d')\n",
    "        if (temp_start_date <= yesterday_date):\n",
    "            self.save_all_daily_data(\n",
    "                temp_start_date, yesterday_date, test_mode)\n",
    "            print(f'Update to {yesterday_date}!')\n",
    "\n",
    "    def update_daily(self):  # 可推测通过测试\n",
    "        yesterday_datetime = datetime.datetime.now() - datetime.timedelta(\n",
    "            days=1)\n",
    "        yesterday_date = yesterday_datetime.strftime('%Y%m%d')\n",
    "        self.save_all_daily_data(yesterday_date, yesterday_date)\n",
    "        print(f'{yesterday_date}: Regular update finished!')\n",
    "\n",
    "    def update_finance(self, year):  # 手动更新，可推测通过测试\n",
    "        period = str(year) + '1231'\n",
    "        self._save_finance(period, period)\n",
    "\n",
    "    def update_cashflow(self, year):  # 手动更新，可推测通过测试\n",
    "        period = str(year) + '1231'\n",
    "        self._save_cashflow(period, period)\n",
    "\n",
    "    def update_balance(self,\n",
    "                       year,\n",
    "                       report_date=['0331', '0630', '0930', '1231']):\n",
    "        # 手动更新，可推测通过测试\n",
    "        dummy_date = str(year) + '1231'\n",
    "        self._save_balance(dummy_date, dummy_date, report_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Saver = DataSaver(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Saver._save_est_pe(start_date='20210701', end_date='20210731')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Saver._save_est_earning(start_date='20210701', end_date='20210731')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Done')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lab",
   "language": "python",
   "name": "lab"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
